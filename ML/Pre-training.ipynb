{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "shQo223S1MZc"
      },
      "source": [
        "# Mount Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cH6cKHqVtSNq",
        "outputId": "f9200c1a-021d-4efb-ee19-8d66e959a593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJGxGi8UqO2o"
      },
      "source": [
        "# Facial sensor dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k5LrmLqcqg5U"
      },
      "outputs": [],
      "source": [
        "####################### raw data ################################\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# load file\n",
        "f_list_Facial = ['Happiness', 'Surprise', 'Disgust', 'Anger', 'Sadness']\n",
        "\n",
        "df1_f = pd.DataFrame() # x_trainset rawdata\n",
        "df2_f = pd.DataFrame() # x_testset rawdata\n",
        "df3_f = [] # y_trainset rawdata\n",
        "df4_f = [] # y_testset rawdata\n",
        "\n",
        "for i in f_list_Facial:\n",
        "    path = '/content/gdrive/MyDrive/sensorData_a/' + i + '/'\n",
        "    file_list = os.listdir(path)\n",
        "    file_list_py = [file for file in file_list if file.endswith('xlsx')]\n",
        "\n",
        "    for j in file_list_py:\n",
        "#######################################ORIGINAL################################################\n",
        "        if int(j[0:-5]) <= 14:\n",
        "            d1_f = pd.read_excel(path + j, header=None, index_col=None)\n",
        "            d1_f = pd.DataFrame(data=d1_f).transpose()\n",
        "            df1_f = pd.concat([df1_f,d1_f])\n",
        "            df3_f.append(f_list_Facial.index(i))\n",
        "        elif 14 < int(j[0:-5]) <= 20:\n",
        "            d2_f = pd.read_excel(path + j, header=None, index_col=None)\n",
        "            d2_f = pd.DataFrame(data=d2_f).transpose()\n",
        "            df2_f = pd.concat([df2_f,d2_f])\n",
        "            df4_f.append(f_list_Facial.index(i))\n",
        "        else:\n",
        "            pass\n",
        "#######################################JITTERING###############################################\n",
        "        # if int(j[0:-5]) <= 14 or 20 < int(j[0:-5]) <= 132: #(1~14 && 21~132 Jittering)\n",
        "        #     d1_f = pd.read_excel(path + j, header=None, index_col=None)\n",
        "        #     d1_f = pd.DataFrame(data=d1_f).transpose()\n",
        "        #     df1_f = pd.concat([df1_f,d1_f])\n",
        "        #     df3_f.append(f_list_Facial.index(i))\n",
        "        # if 16 < int(j[0:-5]) <= 20:\n",
        "        #     d2_f = pd.read_excel(path + j, header=None, index_col=None)\n",
        "        #     d2_f = pd.DataFrame(data=d2_f).transpose()\n",
        "        #     df2_f = pd.concat([df2_f,d2_f])\n",
        "        #     df4_f.append(f_list_Facial.index(i))\n",
        "        # else:\n",
        "        #     pass\n",
        "#######################################SCALING###############################################\n",
        "        # if int(j[0:-5]) <= 14 or 132 < int(j[0:-5]) <= 244: #(1~14 && 133~244 Scaling)\n",
        "        #     d1_f = pd.read_excel(path + j, header=None, index_col=None)\n",
        "        #     d1_f = pd.DataFrame(data=d1_f).transpose()\n",
        "        #     df1_f = pd.concat([df1_f,d1_f])\n",
        "        #     df3_f.append(f_list_Facial.index(i))\n",
        "        # elif 14 < int(j[0:-5]) <= 20:\n",
        "        #     d2_f = pd.read_excel(path + j, header=None, index_col=None)\n",
        "        #     d2_f = pd.DataFrame(data=d2_f).transpose()\n",
        "        #     df2_f = pd.concat([df2_f,d2_f])\n",
        "        #     df4_f.append(f_list_Facial.index(i))\n",
        "        # else:\n",
        "        #     pass\n",
        "#######################################TWARPING###############################################\n",
        "        # if int(j[0:-5]) <= 14 or 244 < int(j[0:-5]) <= 356: #(1~14 && 245~356 Twarping)\n",
        "        #     d1_f = pd.read_excel(path + j, header=None, index_col=None)\n",
        "        #     d1_f = pd.DataFrame(data=d1_f).transpose()\n",
        "        #     df1_f = pd.concat([df1_f,d1_f])\n",
        "        #     df3_f.append(f_list_Facial.index(i))\n",
        "        # elif 14 < int(j[0:-5]) <= 20:\n",
        "        #     d2_f = pd.read_excel(path + j, header=None, index_col=None)\n",
        "        #     d2_f = pd.DataFrame(data=d2_f).transpose()\n",
        "        #     df2_f = pd.concat([df2_f,d2_f])\n",
        "        #     df4_f.append(f_list_Facial.index(i))\n",
        "        # else:\n",
        "        #     pass\n",
        "#######################################MWarping###############################################\n",
        "        # if int(j[0:-5]) <= 14 or 356 < int(j[0:-5]) <= 468: #(1~14 && 357~468 Mwarping)\n",
        "        #     d1_f = pd.read_excel(path + j, header=None, index_col=None)\n",
        "        #     d1_f = pd.DataFrame(data=d1_f).transpose()\n",
        "        #     df1_f = pd.concat([df1_f,d1_f])\n",
        "        #     df3_f.append(f_list_Facial.index(i))\n",
        "        # elif 14 < int(j[0:-5]) <= 20:\n",
        "        #     d2_f = pd.read_excel(path + j, header=None, index_col=None)\n",
        "        #     d2_f = pd.DataFrame(data=d2_f).transpose()\n",
        "        #     df2_f = pd.concat([df2_f,d2_f])\n",
        "        #     df4_f.append(f_list_Facial.index(i))\n",
        "        # else:\n",
        "        #     pass\n",
        "\n",
        "    df1_f = df1_f.reset_index(drop = True)\n",
        "    df1_f = df1_f.iloc[:,0:64]\n",
        "    df2_f = df2_f.reset_index(drop = True)\n",
        "    df2_f = df2_f.iloc[:,0:64]\n",
        "\n",
        "# convert to tensor\n",
        "\n",
        "df1_np = pd.DataFrame.to_numpy(df1_f)\n",
        "df2_np = pd.DataFrame.to_numpy(df2_f)\n",
        "x_train_f = torch.FloatTensor(df1_np).to(device)\n",
        "x_test_f = torch.FloatTensor(df2_np).to(device)\n",
        "y_train_f = torch.LongTensor(df3_f).to(device)\n",
        "y_test_f = torch.LongTensor(df4_f).to(device)\n",
        "\n",
        "# expand dimension of the data\n",
        "\n",
        "x_train_f = x_train_f.unsqueeze(0).to(device)\n",
        "x_train_f = x_train_f.reshape(630,5,64).to(device)\n",
        "x_test_f = x_test_f.unsqueeze(0).to(device)\n",
        "x_test_f = x_test_f.reshape(20,5,64).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mSNUhmGUrZB2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# Custom_Dataset\n",
        "\n",
        "class CustomDataset_train(Dataset):\n",
        "    # preprocessing of the datasets\n",
        "    def __init__(self):\n",
        "        self.x_data = x_train_f\n",
        "        self.y_data = y_train_f\n",
        "\n",
        "    # length of the dataset, # of the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    # get one data in the dataset\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x_data[idx]\n",
        "        y = self.y_data[idx]\n",
        "        return x, y\n",
        "\n",
        "class CustomDataset_test(Dataset):\n",
        "    # preprocessing of dataset\n",
        "    def __init__(self): # x -> 내가 필요한것들\n",
        "        self.x_data = x_test_f\n",
        "        self.y_data = y_test_f\n",
        "\n",
        "    # length of the dataset, # of the dataset\n",
        "    def __len__(self):\n",
        "        return len(self.x_data)\n",
        "\n",
        "    # get one data in the dataset\n",
        "    def __getitem__(self, idx):\n",
        "        x = self.x_data[idx]\n",
        "        y = self.y_data[idx]\n",
        "        return x, y\n",
        "\n",
        "train_dataset_f = CustomDataset_train()\n",
        "test_dataset_f = CustomDataset_test()\n",
        "train_dataloader_f = DataLoader(train_dataset_f, batch_size=1, shuffle=True)\n",
        "test_dataloader_f = DataLoader(test_dataset_f, batch_size=1, shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "44-_hqLh1TgW"
      },
      "source": [
        "# Define Band-Block Filter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVuXTLSMWgel"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from scipy import signal\n",
        "\n",
        "def butter_bandstop_filter(data, lowcut, highcut, fs, order):\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = scipy.signal.butter(order, [low, high], btype='bandstop')\n",
        "    y = signal.lfilter(b, a, data)\n",
        "    return y"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "VXNb6vP_1bj_"
      },
      "source": [
        "# Vocal raw data pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpjNmiBUxQ8b"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy.fft import fftshift\n",
        "from scipy.signal import spectrogram\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# 파일 불러오기\n",
        "f_list_Vocal = ['A', 'B', 'C', 'HELLO', 'ILOVEU']\n",
        "\n",
        "for i in f_list_Vocal:\n",
        "    path = '/content/gdrive/MyDrive/Vocal_Datasets/' + i + '/'\n",
        "    file_list = os.listdir(path)\n",
        "    file_list_py = [file for file in file_list if file.endswith('xlsx')]\n",
        "\n",
        "    for j in file_list_py:\n",
        "        if int(j[0:-5]) <= 14:\n",
        "            d1 = pd.read_excel(path + j, header=None, index_col=None)\n",
        "            d1 = pd.DataFrame(data=d1).transpose()\n",
        "            d1 = d1.reset_index(drop = True)\n",
        "            d1 = d1.iloc[:,0:35000]\n",
        "            d1_np = pd.DataFrame.to_numpy(d1)\n",
        "            d1_np = np.squeeze(d1_np, axis = 0)\n",
        "            path_stft = '/content/gdrive/MyDrive/spectrogram_plt/trainset/'\n",
        "        else:\n",
        "            d1 = pd.read_excel(path + j, header=None, index_col=None)\n",
        "            d1 = pd.DataFrame(data=d1).transpose()\n",
        "            d1 = d1.reset_index(drop = True)\n",
        "            d1 = d1.iloc[:,0:35000]\n",
        "            d1_np = pd.DataFrame.to_numpy(d1)\n",
        "            path_stft = '/content/gdrive/MyDrive/spectrogram_plt/testset/'\n",
        "\n",
        "###########################################Band_Block_Filter##########################################################\n",
        "        data = d1_np\n",
        "        fs = 3.125e4\n",
        "        lowcut = 59\n",
        "        highcut = 61\n",
        "        order = 2\n",
        "        signal_filtered = butter_bandstop_filter(data, lowcut, highcut, fs, order)\n",
        "\n",
        "###########################################Shor_Time_Fourier_Transformation###########################################\n",
        "        x = signal_filtered\n",
        "        fs = 3.125e4\n",
        "        windowsize = 2**12\n",
        "        window = np.hanning(windowsize)\n",
        "        nfft = windowsize\n",
        "        noverlap = 4e3\n",
        "\n",
        "        f, t, Sxx = spectrogram(x, fs, window = window, noverlap = noverlap, nfft = nfft, scaling = 'density', mode = 'magnitude')\n",
        "        Sxx = np.squeeze(Sxx)\n",
        "\n",
        "        plt.figure(figsize = (6, 6))\n",
        "        plt.ylim(0,1000)\n",
        "        plt.pcolormesh(t, f, Sxx, cmap = 'jet', vmin = 0)\n",
        "        plt.ylabel('Frequency [Hz]', fontsize = 15)\n",
        "        plt.xlabel('Time [sec]', fontsize = 15)\n",
        "        plt.axis('off')\n",
        "        plt.savefig(path_stft + i + '/' + j[0:-5] + '.png', bbox_inches = 'tight', pad_inches = 0, dpi = 300)\n",
        "        plt.close()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EXiv8lDO1u_z"
      },
      "source": [
        "# Vocal sensor dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qExwntozBZwT"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "%matplotlib inline\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "trans = transforms.Compose([transforms.Resize((100,100)),\n",
        "                            transforms.ToTensor(),\n",
        "                            transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.ImageFolder(root='/content/gdrive/MyDrive/spectrogram_plt/trainset',\n",
        "                                            transform=trans)\n",
        "testset = torchvision.datasets.ImageFolder(root='/content/gdrive/MyDrive/spectrogram_plt/testset',\n",
        "                                           transform=trans)\n",
        "train_dataloader_v = DataLoader(trainset, batch_size=1, shuffle=True, num_workers=2)\n",
        "test_dataloader_v = DataLoader(testset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = trainset.classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeJWUzviBadM"
      },
      "outputs": [],
      "source": [
        "def imshow(img):\n",
        "    img = img / 2 + 0.5 #unnormalize\n",
        "    np_img = img.numpy()\n",
        "    #plt.imshow(np_img)\n",
        "    plt.imshow(np.transpose(np_img, (1,2,0)))\n",
        "\n",
        "    print(np_img.shape)\n",
        "    print((np.transpose(np_img, (1,2,0))).shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NvqDho5DCR-p"
      },
      "outputs": [],
      "source": [
        "dataiter = iter(train_dataloader)\n",
        "images, labels = dataiter.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 376
        },
        "id": "5e0T0hJfCUGt",
        "outputId": "a2718c02-5352-4a22-fc1e-9910a0919ca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 100, 100])\n",
            "(3, 100, 100)\n",
            "(100, 100, 3)\n",
            "torch.Size([1, 3, 100, 100])\n",
            "torch.Size([3, 100, 100])\n",
            "    A \n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO29Wawty3nf96u11h7PPtM9d9S9EkmJtBxatiKbkGkoCALRThTFMPUgCHIMg3AYEAGcWHYMOFTy4ATIQwQYlvUQKCDEGEQgRLJpISQYw45D0w95CCPKVCKRFE2K46V4J97p3HP23muqPHR/Z33r219VV6+19hr27j/Q6LGGrq5/fUMNHWKMdOjQ4eqjt+kMdOjQYT3oyN6hwzVBR/YOHa4JOrJ36HBN0JG9Q4drgo7sHTpcEyxF9hDCT4UQvhxC+GoI4cOrylSHDh1Wj7BoP3sIoQ/8G+AvAM8Dvw385RjjF1eXvQ4dOqwKgyXC/jjw1Rjj1wBCCL8BvB9Ikj2EGxHuFEavG6HQ4tkOaTSV4zJY9Bt033Y1kHJ8nRgfuIW6DNmfBb6tzp8H/uyFLITwIeBD1dlt4D9riDaaPVQv4uXfe7ZDGqlyhLIyTIWdLpaduTht3JHuu7aBfNv/KfnEMmQvQozxI8BHAEL4vrhYxeg+/PJIEdUjWyw49s4XQddgrwaRJp4s46D7DvD96vy5+lqHnYfWAFIaVUfOXcMyZP9t4F0hhHeEEPaBnwc+uZpsdbgcaALnTKNIpYHpfbPk6LDdWFiNjzGOQwj/OfDPgT7wP8cYv7CynHW4JJQ46TrV+ipiKZs9xvhPgX+6orx0uFRoAjc56TqSX0VcuoPu6uAqdBE1EX4X3qHDoujIXowSibgsSvvBV+kF73Bd0JG9FS6TIG0GvAQ6snZoi24izNagI2+Hy0Un2bcKHeE7XB46yd6hwzVBR/YOHa4JOrJ36HBN0Nns1xpdX/t1Qkf2a4vUbLeuAbiqWDPZc/Op26KpAl7mQg1NaJO3XD4vY0opzKy33Mw2m+ZVmAiz6YZs1aMw24232GHJnnvRTRJdp2/z55G8zcIcqXjb5s1OYS2phFNzvkvIvd8qynRVKM2LV4+a878BsvdXFE9OypR83MtEasEHb564RzYrTb3ri0DSKZXsOv0SqbhI2S6zQk5TvG00qFUNVS6pe02NuyfIUnXH1ol0+htQ41fZAbCI2rMupPLWo3lxCB3eqs/LEt1LL9XYeOdNK960RZMquky8y8axTJqpe7nG3T6vCZxroMvqxJrJvm6bz6u0pZX1svKpW+5URbfEbiJbaV5LbXTbuOSWptLXF/FFtM17Dl68ljSriLsJJe/ukbVpCbCmepPHBtT4ZRYnbAuvcSmVcJdFdkuIUjW9iUi5hqGE5BLWrlTTphzaqMPy/KrjtPHmCLQJ6S/5sPnKlcVqHLUbIPu6Jbut/KXpX2Y+pzS37Ba60tvW3VPzAz5RSqbpalWzVAqn8pZCqVnS1oHWJl5P+jfF3dQQl6RdGq+Nf7k6uQE1fp2S3UvfO94ExHaHcqmSIndKzU8R3dqPOUeg3G/6bpdVtpdl+l12XVhlvtvElX5uh7vedh1tpUoqjhK/RKqrLdft5kmTZfJ6HbBNwuQiOrJvDKXqJizulBMy95w9ah/NJvf0eUf0NHajXDqybxRNXnb9XFsbX8fbtE3VviQ/HXYRHdl3Eot2wXhEh5kU7zEjfM6TvxuSrMM8uimuO4FcN2GbPnMd1trtVtXvJPtVQyfZtwKl3WMaTd1AngQvzUfKmSfpdthFdGTfOHKec4tUd5sXZ27LpW3zoPeLj97qsHl0ZN84Us63ZW3k3IAbzzFoPfLetmheOmwDOrJvBRbpy06p1fZcPO095kfu6S64qJ71SD5l5rjbRrKXDAPe5vjXg85Bt1UoHVHXZId7jjmvUciNvkult42Ou6ZhxptKe7vQSfZLxWVPtChxmqXU+LZOuzZpbgtWOVx10YFN24OO7JeKVCVpQ/xVqKDXoSutk+BN6Mh+6SgdJVcazyLDZPU5pBsAa6eXmAMddgWdzb4RWBK1nfWWQ27km5znVFKP3B3hrwI6yX7pKCGynmoKPpk8KezB9oV7w19T/eW5BSu6/vVdR0f2taDEyy3n2s5fxjHkSWIrvXNqfIerho7sG4E3EQUuStxlPd+eap7rIUgNovGud9g1NNrsIYTvDyF8JoTwxRDCF0IIv1BffyyE8C9CCF+p93cvP7u7Dm/oas+5bx1rqXAl49+1s22qNs8J5w2m6Yh+VVDioBsDfzvG+G7gvcBfDyG8G/gw8OkY47uAT9fnHbLIDWHF3MsNU23bKORmtAmpJ8w3BF56JY3LJrELedwcGskeY/xujPFf18f3gS8BzwLvBz5WP/Yx4GcuK5O7ixKvtydBcxK1RMJrkvecc50XT+KnHHS5bZPY5rxtD1rZ7CGEtwM/BnwWeCrG+N361gvAU4kwHwI+VJ3dJt2+lHigU2gaQZaLpySNVPxNYXMDaoI51vdTUj/VeFjHnk3HPivHbbryvPQXGZHXBqXxproZ4eJKvruGtmWbfraY7CGEE+CfAH8zxvhmCLNIY4wxhODWnBjjR4CPVHE8Gy/+/qmpu6nkRVMrn1qnVBP52sa/SLz2ei7dkr5t7Vn3NAAdNtdf3tQDYBupnCmyLFKNSKqsPCnedgzDtsGWwfLvUTSoJoSwR0X0X48x/lZ9+cUQwjP1/WeAl9on31RZ2nYxrfLZZcJ4hE5J8qZ0cw60EulcGo99dlNYJi/eu+4iUn6c5dAo2UMlwj8KfCnG+PfVrU8CHwD+h3r/ifJk236UlEratsLbY4kzFb/sSyS7PtaS1ranKQlk08w56FJxaVgfQOoZ/R4a9t9iXj5KzI22pljKT6HzZOP1yqlpnfs2jW9KM1o2/pJ4U9/Iq3t5lKjxPwH8VeD3Qgi/W1/7r6lI/o9CCB8Evgn8XFGKFz5MU2WWe1ZNzamkpbAV2WIVqmpKLc6RpknqtlHpFtGObFmXhE19v0Xise9qv38u3svQThYh+6rjXYNkjzH+X6Rr1/vaJzmRmAuejfXzTS3jotCF3ETIXPpeHHJs89/UEnsNmqfW2WdTzr7Uvab4c41viaRaBF64XBmXxpF7bhVO4GXiX0VZrU6yrxCLtozrsL1WkUZK07AkKflQy7b2VhJ66WktIUc0G2/uucv+VquOf9fy25RGOr1uuOxa4JkhbbuUmj6op+anNAprA6fMiKa0vLQ7bCs6sq8Nnv2ZctR5SPVxp9LywnmE1w2J3ssAG0/ye+TuiL7t6Mi+drSx2XPPLOOQtItYpCR74KJXexVOyw6bQEf2rUIpids843XZ5Pr9RarLL6FsY9ARfVfRkX1tyPWLWpW6qVuppEsr4P+9Ve9TpkGPdGMhzzV1W3bYNnRkXxtyqrs30MZzgpU46mycejJMn2ayi62eyoeXzqr7nztcBjqybwRaaqa65bxzS/iUhPfUdL2lyC7qu/2ZRNN75PLSYVvQkX1tSHnhPTQRJ+eZ90yEnrNp0uvGQxM9MlPptaMulbdOtd9mdKvLrhVNfdeeV1wj5VTz0vCQkvRNTrsm2LAdthGdZF8bUtI3ZZ97aDO009r2iw73tOFzWoTnV+iwLegk+84gpyIvI1FzEtlrNHSYTpLvEjrJvjakHGbgS0iLJmlv4+jj2+megy61b4POI7/t6Mi+FuQkYcm1UjVfhy2xyUMiXKmXvU2j1GHT6Mi+NuQIU+LFlnt2+Kq1/1HP6T5wTyVvGl2nu+FyDVDXBbcL6Mi+Vlhit3Volc5Akzg9wttncoS3NnrTwJ6O6NuMjuxrQVPfeunAlVWk12SPp3oHcj4Dz0PfkX7b0JF9bViWgN6zbQnVxvFm1X9LeE3qRfr8O6wbHdkvYBkylcRpz0s84J4KnbL1dXwlf4zJqd6r1jg6bBId2YF0N1ibCSGp+NrmI3XNc9B5M9Mkbd31luqGs3+H8RoB68Vv8sx3jcC2Ys1kX9dAjJIKlyKWd71kPHtpPDa+kkEyKSeYPU6lnRoBp/ORcth5aBrWq/N6nbEJh2W6zDcg2Vc5aK+NNEmp0t7eeswvY6Cht665pNu01rxnL3sEn5p7E3yp3gYl4/e94+sGz0TKjZdI+WVWV4bXbLisN7Bk3emXoGTQjBzb97Eag9ft1hR3rpyuM4FLUVrH1luWG5Dsq1JrVjE8s6llXUVecxpFqXfeVp4SX4J11NlprZhjiU+nNVX7gP9v9xx23X5fpB7keiZSkj01VmK12GGyX2ba6/DCe+el8Vn7urSyNElozyknDYQdSZeyR3ed4CmUvpfnRylV5e311dr8O/KTiFWlvUl4RM+t2+6hzWAXT42XlWhSYeWZKZV9PzWb1X68notc/ncNixBOj1rU8UD7clmkHNNhuq63S4XXNYa65qnQJRWjVDro+5b8XiW2DYPee41DrtfgqmARgm5nOXRkXwtSnlZ9zfYA6OOcut/0rF4WWj+rpbyXT5vfVfoxOmwCHdkvHZaAWqp6XWeW9LlfD3uOupQdrZ+x68J78MyOjui7jI7sa0fOG2/7z72GIhev1SDscFkvXWtbarXdO+6wq+jIvhHkut3k/iLOoVQfvCW8TkND2+klNnuHXUJH9ktHrs/cuw8+uUo99Lm4rM2eSjt1nDpf1NvcYZ3oyL4WNElyuGhTw3Lk0YRO9Z9b9d6T4qlGp2nfYdtwzYbLbgol3WietF/FKKqUAzCVjyZnX+56h21GMdlDCP0QwudDCJ+qz98RQvhsCOGrIYTfDCHsX142dxme5EvZv3pK6sDs9dDWJnvfxqE3z2nn5bWz1a8a2kj2XwC+pM5/CfjlGOM7gdeAD64yY1cb61R5c554jU4Nv+ooInsI4TngPwJ+rT4PwE8CH68f+RjwM5eRwasHK+HtkNRJvY3VsR66WiptvfgnzmaHxtpwnoPPwypNjw6XgVIH3T8A/g5wsz6/B7weYxzX588Dz3oBQwgfAj5Und1eNJ9XENpWtwNtLKlSRMvZ1N7QW+to69GcVhPRvbEBHbYRjZI9hPAXgZdijL+zSAIxxo/EGN8TY3wPHC8SxY4j1fVW4qHPIUf0lEQfq01rD97kl0Vs9Y7o24wSyf4TwF8KIfw0cAjcAn4FuBNCGNTS/TngO5eXzV1HqqtLw45+8663gZBVpyvn3kKUNpxF6ZTWjvDbikbJHmP8xRjjczHGtwM/D/zLGONfAT4D/Gz92AeAT1xaLnceqYEtJfbwshqAjiPniU/lycs3DccdthHL9LP/V8B/GUL4KpUN/9HVZOmqIUfuUsJDs2bQFKaU8F7+vfyVdCV22Ca0GkEXY/xXwL+qj78G/Pjqs3QVsU3OK50XO23Vc8yl4rBYdDz/VUXThKP1oxsuuzaUEsEbUbdsunrYrDebzgtTKq31O11Xwntl2TTxaP3l05F9bShVv5smyljJbKWyNzzWLjZpzQFbCZschPb+dSa8912bTKTNlM8GfhKxi8PxF5GypRLakhKah7TqzU6a8exz2fdV/DqMjmuSeI+md7GEt9dsPKm4Vj0op6kHIdew5uLUPR2Yvb0m6cm3alo4RKPUr9L8/AYk+yo/Ztu42raki44KK/2QOh1bSTRJ5Zrn0LOE0mFTZJdnvEUk9UqyOl3wy69EgnnP5c5XacJYwuXSbkt2CWO/WyoePYipRLKX5KtcS9iAZN9bcXyQXqXVItfK5ypAm0qQOi8hTJ9mtVtgJbon2fvm3K4Tbxeo0ANrpDHAPOPBfofcM/ZYX2tT1jl436FNT0fb+D3pnqtrpb0vet+Un2ZNcoclu6f+2sL0wjRVWH3ephJ4tq5ny+p86nRteqnNS9d7D0+y2ziielY78ZrWifc0lxSBvb2HnnpmmTqS+w6pOrHMd9bx2H0TmXN50nlryk9Jehshe24BxbaQwiiV6DlJ632spkq6iCbhPSPv4KnP3gfPSQb9PpbsnuTV8XjrxNu0UmWZI3+Jqml7DBZBU5lY6DKGxb9z7hulUGpSljZAzdjATyJWRfYUGRYhvD72JG0uzqaKoONM3fNsby+PGlqt9tRWT323anwqTm9LoYn03nMplDSwTfkorV+23Bf5zikJXFJul4V0mhuQ7NbbuwxsxSiVpN55So0vjavJPMip4VLR7Cy0UmLi7DXRbaXWKnMqz9ocKJHs+rjZfkwjJI5zKPkOuXSa0svFb/O7SF7Wgx2W7KtGE1kX/XCljUZg3jFWImmkPD1Joskujjp9vamyW5KntCfPUVii7XS4HGyVZN81rLLC5iSeJkgbx5aGJavucvP2HoE988A2JPq6OPM8dGTfJnRkXxty9qzc9yRzivCpc61+6zXtAtXnLiX7ROU556Szx6lnO2waHdnXghLnnWer5kyAnNe5qWvINiSeg7CJvJ6d3hF8m9GR/dKR81an7GivAUip0alrHuE8ost17QOQwTXaJ6Cf0/F7Hvxt9ctcb3Rk3xiW6U9uQorwHtm9Lqhcz0Eu/g7bjI7slw7Plk4RyZIn9awmZgop+1889HpUnTwr13PDZXMNid6XNgTrbjBKy+zqoSP7pcNTzZcdeGJtbK+bzqrpmuQpsus86L54G7fXp59LPwXdYK2TaLnxDuvOy/qwgYkwuf7jTaKNSl3yrJbkGrk/uzQRVvYiaYXA0gUm98XzLn+E2av3B/VzAy6SXTzwssH8pJiURPeceKVoev+2KDWNctrSotjGOj2PDUn2bSV8CZq6wPR1r/LlJHyuonqS2qrq2ua2XW/690+W7N6MtomJz2oUKXJ74wU2hbbpe1rT1cEGRtBtayG2sTFLJEjEr/Ba9S3xwufiTnWPid1t09Lk16q8hLUNQKBaW14jN0FmUQkv4VeBRRuZq9912NnsS6OpYnjSV45TW9v0dXeX7QKz0tkOtPFMBZg3D1KETqn0+nydSJX1onFcLXRkXwiljrRUOC1NNeFS0zxLbFtPK0g1Jt4sOGsC5MJ6/4+3ed4kaRZN++oSHTqyL4FFCS9hc11X1olXQiSP5Da8XdBCq/Goa7bRScXdZpbeJqV8B+jIfsnQktwi57jznrG2aKoye+E91bptV5l10tk8NanvV9PptUvoyH5psOTMee3t/VLbvaSrTj/b1gGlw1ivvE6jNL6O8JvELq7rfMXgDVDRKPHQp6Sr3fRyUyX/Y7d5LEnX3k85HhdxRnZYBp1kXxtyUtWuHOPtPWJZSQsz55nY5fJrZup9ZNb1pp+P+L9x9rrYmt4r1UDlTIymPvsOy6Ij+8rQpKYvGl9OfbbHuT7v1LUm5Oz9Jkehd66v5/rEIxcbsg7LYEPDZRdFSeW6TKTyX+qRzt33VF7PK2/TFUJo9Vzfb+obz+XT0yiaHHxNmodtqJpMBP3MrhHf+16lYZrqUepbpsPt0LrxOSmwLsKnXBwpqdsGtrtMX8upv57Ub0MKed7G5+WrKQ6dPxu2bZ4Eue++7Wib7xKH7uLYANn7zY+4yFWWNgVT0mXlXUs5mUqQ+og2fGowi41LS3AZw95T1yOzSTB6QozY6jnVWWx17x3ED+A58HJjB3S+yezbOPG2vQHIaYC5+lAi0WW/1ZJ9GTU+JbFW9dGbKlqO7J7dnLqfc15pskPz75Q8FV2u28kvmqze++Tseat1pKRt7htZGzxnUuj4S8p8G9HGnMuZahaLmGQVdmwizCrCltiI8lyTJM+tv15ia6bia/oVkpbgItltOnoBiqm6hro+Mc9ob/yovjZS93S6kp7WMnKSXT9vr+njlF/Ce36bCd+kkUTnOPX+uX0urXlsQI1ftZOlKT5P3fSgbV/PzvSkllaf5RkbZ1O6GnbdeC9Oic8ju34Pj+x2xViZty5xjZmRfaiu6fTsZlew0fC0hyboytwk6bbZnm/SQlNakK2vsm9S25vLYcf/9dYGJR5dq2o2wY4NF3iVtClOT33PmQl2llsqTg+ezZ3qU0+p9zaO4Fyj4Lwk3yXfbtthv2VbP5PXCEg8vcS9eRSRPYRwB/g14Efq2P4T4MvAbwJvB74B/FyM8bXmTG/ryqOLVCgtgS1KWvGUTe/Nfks5uFLONO9YwtjKk/vHW6ohsOl5pC4ty5zNmlNfdxltNZLce5dxqnS47K8A/yzG+MeBHwW+BHwY+HSM8V3Ap+vza4gcCWCetKlNP5tLJxV/6jzlS2jyRXjpphqCVN5KnE067ZS54u2vAnKNa6qcS+Py0Uj2EMJt4N8FPgoQYxzGGF8H3g98rH7sY8DPNMV1PaC96npVmL7ZdHeYleBeQ5BKy27egpL2XpsGSCR70/BZ7bcoTdO7blFa4Ts0oUSyvwN4GfiHIYTPhxB+LYRwA3gqxvjd+pkXgKe8wCGED4UQPhdC+Bw8XE2utxop1TxHpqb4PA0gZ4/LflWSI9folLxvKo4m/0lH8FWihOwD4E8Dvxpj/DHgAUZljzEmv0yM8SMxxvfEGN8Dx8vmd8vR1gljbWIbTxvouMSjPk5s9p6sKOt51oWwus++SUNYNN926wi/SpSQ/Xng+RjjZ+vzj1OR/8UQwjMA9f6ly8niVYBXYZvs3lJ72z7b5DVvS6AmDaXEFPDys4ym0WERNJI9xvgC8O0Qwg/Xl94HfBH4JPCB+toHgE9cSg53Cjmi5Sq1tbVTm7Z1vXCeHVwSrw5v38Wmo30O2u+QG467KImXaVw6WJT2s/8XwK+HEPaBrwF/jeqr/qMQwgeBbwI/dzlZ3DVEqoon+xJ4zjl9XT8XzbG9ZuNpQw4rxUveIXCx68dqEstgEbOgg4cisscYfxd4j3PrfavNzlWAJVPJTDmBnOf67+W51BBVu6Ck/imE7K0EFqk7YbbghZDYDpf1TA9vGWvvfFVoKpt1pXVZuJwGq1u8YmXwpGWT/ZojvBe/RYpIWp33fgzh/RFGpyErzArJIe3AS5kmKV9EW3haSw5emS6KVFptelPaxm21tdWhI/ulYVk70lZyq1KnKpxIfSGpELfJzrc2unjo++qaroQ5X4SXr2VREtdVce51kn2LUSrRS5GyxW38onrrcJ5aL9et404G9EhYLe1FlZf161IaymUSvW0cqyZJG7/L9qMj+8rhEdN7JlcxraPNiydHLk3mgdrkb677zKv2Elb/182SvE0DpklyGQRcJ7wu0WUbNRvHZZXVPDqyrxRWzc4Rw/Om27A5outjTXyRzvKr5j0qcu8Bh8x+3ay7yiT8mMoh12NG9j4zqT9Ve/seMP9vuVJfxK7hMjSW9WgQHdlXhlz3Wcq55h3ra7kGIyUZrFPOG5Nvl6nSjYU45vomvibpnnI6prrwrgr5LwOXI+mvKdlLCNQmHu//ado21gTJdUvpeyX93Pa5wIzIWqof1Puj+r6V7CKRR+q95FiqiLybTtvm31ufTq57edd77951Qa58VodrSvZ1wrPhm+xAT33PhWurAlqPPFx00JVK9FwaqfNcY3Z5XU/bifU5AK8p2RdVK3PdXXYvFdZW3pxEs5qCNQd0fBKHlabSHy52u9jf2sMu3XO6Ww0VRmzznjlvqpg5Vd42XLmBQ9eF6IL1vO8VIXtpJVxF/ItKU40c8VP2vicZS+JNbR5S6aUchfa+veZpIpKvUq/+dUaTr6cdNrCUtF03ftHM57zVHnKV3MtHkyfd5sNORLG2uk3D/lTRi1eQm1yiV47Vqvie2sQpJ/mRcDasnupqp91qSa/Tt8cSn31fjSbHY1OjVII2jfEmG5UmR67nrEtph/lGdAOS3Tp5FpWQunCaJu/ZypNToe21XEXw7Fu7l+dEbbUfralS6/h1nqyJIHtveGyqImlSNs0ht+/q5QGav2lTA63LaR1kX1ZLWwVyfhFL9lQD2/weayZ7j8oTLPBaqyZ4UrVUjU8VVFNaMXPubZ5X3lOtvf+zocLqCSu2QUup6raBGQPnzCa5SJeadMPZfvah2ssiF9oHkPI/eO/TtnG1z6a+UdO3a9Ic2sZ32ViE7N7xVkn2QNUFJPBaJ7hY+IvYkTksIulL7FWvC66p20mTRMdp48nBxiHPyxj5ITOHnBC2z6wBkHCjepPBNVqt1/nx0rdk9xoE+/4WbWzUUo3LC+Opv23yVJKHJlj1valul5ihW0V2kR76vOkY0rZsW8KnKmCO7E1pWJJqqaz3TRqIVsdztn5Kimq7XxMzmmveApj2/aXvXZNdJLxH6iaJ3oaw+t2bKr1HgBzRm75/SYNu42xCSd303tlLK0fm5rxsgOyjhvs55D5GqmJ4+7bpefGnKp2QXavItk/bS8cS3ar/ML8+m/ypZWye0Ta7ncpqV7aVvQ1rp7Vqoutrcqx/DaXfSaDLp0laeVqRLn/PDLLv76XjNUSphsKG9+JrA6095QRZKh2b11zDkM7bBhx0k4b7i6hTpTZaG3vN8w00xa9Jq+/pyqmfs+YEJrxnpzdtqLBWontkH6hw1iSx/3rXc9y9paVzmpq8V1ODq+PRffE6fO6bWkeojgtzPUd2e92ilPBN71zaqOTKsAxbJtmXxTIfZdH45bq1r73KZiuhRxKdjpU0nkSTc72SjO4ik8Uq9ISYg/raPvNq/Fi9g6xQI+mLs05seY/oqS43r0H0IPesSeKVh1dunqrexrQoNQfbosTcLPHL6Ge9d7XH89ixv7gumuZlovQjeR8oRfiUhEmVn6fy5yqz5xCKznUdT6pypZB6JqfOCtH1++T8HVYKelpAat8mz8ugJF17L/UN9Hmq8doasl82LpvYKQlcAv1X1ZxE1BXbGzar0xY7PDphJb6SH0DiPJOqULk4PDXbxo+5n9NqZJ8as4+5ntOavHXytuW/g7qhujxcMbJvAiUfyrbsKamu1XDP/veksT73UKJCevnxNk02TRiPoClVvkkCeddt45B719R9T1oubv+2R8m3St1LmYZtNK2O7EvCVixPAtoJH/oZ7V0X6Aq4SGvvrS5r13W3vgXt4R/W2ynzA3Ikzj3zjtpbr/8Vn2vQSqCfk/QFWtVHHefse+sU1VrWZUp4j+TePvWtU+VWoqnNoyP72uA1DJYITXZdm3N9PbWl8un9gklMBpt3a5PKDDlrQuh9G3hhLNl1Fye0K5t1SnhdB4aECDkAACAASURBVKyW5h3bvC2X347sS8GSR0vNvrpm1Vv5YDKCzXqfc2HhYgOhrzWpiBKvLHChvfEyceaQqmqM62M9bFZLQ5HmI7XXa83robalaFOJrfakG5pUuWlYk2SZRqkJnj9FYBsvHUb2ths0FVcaGxguu4hq2qbwL9/RMZ+Wt9k+7iZb1qpzHtnlWdnbPnsvvqY8S1876lyPqpOuOE1k3ccujYA0XDA/vLZp9pvFoo4q7evQXZxe2Qia1OZl0NYml3SbwnmNVbmk34BkX+Rj5lpn+9w6yZ6yj1OzzqxKJqQJJr4c2a0E0s482/pPzKb9AzkbV6flhZf0pQ9fyK73enFK7wcT3rvYSlsivayE1GG9upCL0z6/LPFLzQlPXS+JLxXex46QXZB7qSZbdNWwqrsluJBAExcuOog8AqYcabLX4+H1SjL6OT22XRPVOqM8wus0bRze+0segtn3VDj7+yg7rt4jvmfL5iq0nQyk38t7Xy8+3SgvQvZUvkuQa3y0FNfPl5RLhR212XO2zbpg7UXPOaUJkVPTvErutfKeU8/a77LJCDm94KRsejSdHhvv9UWLqn7O/Bh5a6rAfAMV6/glDq36i4mg9znPeIlN7ZEzJTGbtMRlJLrVTEpME28OQCre1PffSrKv2vlRUkCXBe9DTtR1q4brCRFeXHZwjZDKe9YjvtY0Dqica4fAMRW5j6kIeMxsCK1unOzwWCH6EHhY78UZpyfbyGq18vOJQ/Pe1saXabd6+m3peHt7LaXp5cyBEsm9KsKnoBvm3DRm71t7ZdKMK0D2VMvptfKrRqlNqKWknGu1Wq5bVTilDqYkvI07RQ7Za60D5k2S1Og9rbVYaa3Vec+EmVJVuYl6dsC8B9/TAqR8PJU1911zNviianobWM1CYK81SX+tISye5ysyNt7avLn0VwWPiJ45IZXfEt0SXsP+g83an5bsmtz6h44yq806yLStPWD+u8izooKnBuNYP4DY5+KU02FkHTzduAiRRbKLmSD7kbonDYGUh7eXstF7nGfk/LKJnkrb3kvVV6vRaVNwsbzvqM1uoQutSaVbNXJE966n7Eg5zm2L5k/CWqmtF7iwpkdJ2lpjEZNDnwvBpaGxcUoZCJH1TD3dqOi91ZYw11PaVpOdvgmkytUTJCWmSx5XhOzQrCqtA1o11h76lApuVW15rm/iwYTXmoGWllMTh/6ho/3vm3bQ6TyIXZ2brqvLVmz7wKzPXf4XN2L2bzmdvgzoCczWJNSSXvwEIuXP6vsydNdT+ZvIvIn64OXBNqDWZm9q1D0zsQxXiOzQLOFL0VaKetIvJR010b3RW7bB8FRSa3fbsDDf4Ojx8baL0Ep2K91z72ylrI1DD3IRSOOl1Xq5LuH1stcjZo2QNxRX4s6Nb980yS0s2b29hmeqXJJkDyH8LeA/rVP4PeCvAc8AvwHcA34H+KsxxmHrHKwcOTto1a27JZ0n0e0adNrrbaWS5N9WZk3qlL0peZFVaA6ovO6yaa/8ETOpruPVtrYlu5dXmC9Tea8h8xJer5AjC2cc1ddkr38nHer8ypBbkfanVKTXk3TG5JfI0nnbBOk9YmPOvfvW7EOd22fL3svr15nPTgjPAn8DeE+M8UeovsjPA78E/HKM8Z3Aa8AHi1JcC3JkKFGTSmzWXINiN89WLrWH7Qbpj6vTsv9l934akRoQ5NntTekKpFEQJ9t5vZ3W20N1fMasO0/eT4gvXYdHzBqsG8warkNm4wfknezsvrYa2qrhkbckT144fV6iDVxEqRo/AI5CCCOq0v4u8JPAf1zf/xjw3wK/mo+mSTWk4L4Hz6b00hUp1KSe6ria0pRjK3GFeNaTLTay9mSP1T4y/290TWBPXbd5FkeWeLMHzGxnsa+tjyBAiBBFI4hUJNN95nJd0pmaY33NlpGWrtK3Pq7zJHk7Yyb57V9s9KCgaZ23SR1GGpShOpY0pCx1uXhOPc9bvyhyRNTlrtPQ3ZUlRJY6IU5ROx/ARyPZY4zfCSH8PeBbVM3x/0Gltr8eY5Ra+TzwrBc+hPAh4EPV2e1sZtq2VHUO8dXzVCHlWk3vI5d8eGuD67Ss5NTPa7VTx6UX5dTKl827fnetigdmjiyt5mqimyhDnde4V8chjjMh+R4z55044qzWkbObYdag6TXr5XzMbKbdQb2J/W6deaLiC9lPmWkQ4hj0GiGP3F4DtYxGkGuIdRpWMFiTUB97313H3TRCs0Ij2UMId4H3A+8AXgf+MfBTTeEEMcaPAB+p4nouppNctICb1NuUupxqWOyHyMUv8WqbVKuTdmJMTmuQcJo8nmTXxIrqel+dB+alY30c9iAMIPQqcmtnfwSmvVoQyruMmVft5T2kQbDj27X09MpQv79uMOQd9AAb2UTai2miy09MEVS+JN+iBZzje+7tsY53FZJdH8u7eyMkvfT0fa8RwNz3hN1FlKjxfx74eozxZYAQwm8BPwHcCSEMaun+HPCd5qikEq4KurC8gku1kKkC9NRxe13f055lS3apiJbsuuLrhgJmf8vRLba1mTWxxKGmz+VZ3dVVb72a7IMe9AIMwnwbMgoV4WMfptau1w2aLQuP9Pbb2HH32twQTUTUerHZRaUXc0RIL2UqEl/uyfx7vcKOdNvZOfaipei8NHXhLSOQ9LFH9BzhJW2vHqeE2EWUkP1bwHtDCMdU+tL7gM8BnwF+lsoj/wHgE81ReURaFE1ET4Wx6m+TZIeLLb+ND9IahFWvPcmSisf2v2rbzEp5Lel7zLzutYMrHMLgAHoDOOypofFhFnQYK4k/CTDqQxxU2xzpUWlaLaNJUtpwGnpOgfZlDKjIrsfeW+eiNok8v4TWjLwGHi6WaQ5tzUwdf1M8TXFbYWYbhTRKbPbPhhA+DvxrqtL/PJVa/r8DvxFC+O/rax9tTA2Y//3TMrCtZROsVG/siFBxN2kN+pqVxJqMMK9OjtVzIqGs2uwNqsHEoW1/kebHwB3gFvAE9Pbh4Bj2enAnzCbDab/daR182IO39mESYXJYp7fHbM1/TzJqkqd8IbaB0+Wmu+tsgzcw+z180uuy16P2dDna4clWI9H59eBJWA+24UjF6WmcXlzeuZb6zQKvyBsfY/y7wN81l78G/HhJeBUTzU6ctvG1eVa3hKX5yLX0XotqK4Nna1lprZ1qoprDxUrgVSArXb2FJkIlsWUbAHs14Qc6SKid2AF6os73IQqRdMNlR//p8rKwUtMLY21PXXa6fHpqb/0iqYY2Mt8o2gYndexBNyBNzzU1Gk3HOj197qXVjA3/2HFTaGt72cIUKZGymXQFHJhnRO3UKvHIhBfC64EvumHQmzBVpp5KGe8z64uuPd4hzsbbHAEn9WPCiYd1cg8DnO7BKML4gHnzQQa5pBoe8NV4T+VH3U99E13GdpyC3utvoveeVMzlo4T40vCUoKmxB78OWdhBQe0HCV2x4bKl0NLDu14SXtvOHqzdbW3yyLz6mZPYVurZvHr34vxtaX/0n6DEB6YF9hAYh0ryxx70+jDR6rJXEb18ee+S0wJS5WhVVS3pU2UMeQKl8mbTbcpTG7QVMKk4miT7kmp8B4uUDWXtTO1U0pJcJKRsMrdbbGCvAbDpyjPSXUW9lxFltWOudwSDfTgcwN1eZco/RTUY7RaV8JdoH9TX71MR/rQPo5MqvuntSr2fm4Ka+v1201DVRciiy6KU2Dl72Daukk+9XyW09pKrPzjHch6dfTk6si8FK131sTcMNaUNyIAVudckBax2gIpfd5HVXW29Pgz69SjTMD/6VPxvkiWxBo5qyT7Yqxx1U72klXj1crBEkuNFiO7FXWIPNznSFrd/y5H7np49HpzrFosR/pqTfdEPayuTJrYeky52t9fPrgfeRHxPsHU8eaq99i4HZuu+HwMn0DuGg3046lde+BPgceAmcLd+TPAWs0bgHLgf4P4A+hEeHMM4Uon9szqA7i7T7yDIqcH23qImVROsRuA1QqtOUyNlo3tkto2TfkZ33cq9TrKvCcHZvG4zPSAlZZvrsfBahbRdSjpsarSaNDi1UR72oD+outyOgBuxIvxJqNT4Y2Z1Sg/gu0mlth/2Kpv97AAmY4gi3WVGm36XVEVsqpSeUy2l8jYhJxGtM+6ykSN6yrzwhken1Petluy5l0wh9zKr/GBN+WlSGz0nkYTTfb4iDfWQ0FPmJaNuPKyDTpMqqnuPRsbU5w+A+7XT7RY8HMBrezCspftZHeQGszZFJqUNqW72IhxMYTKFh4cw7sH08Zrwb9WbeOdlcQkZ7qp9EF4ZptR8r2xLkHPIWeRU4FS4tg62krpun5FvLufWD5JrUJuxoXXj2xRc00utgvCleUqllbMNrTSRfl5ZiWVExTAdl3i/9XBYCW+9xzpdaURiHef9qp/8/BxChNcGcB4qqX1eBzljpgwM6/PzulL1IxxMYBphcAj9fYhTiDLt9LAO9ID5v8foRk36xLV/QZeHfR9PenlIOetysHXJS6dNo+HFn8uTZ7pYzTAlMFLSvFwD2gDZ7TJNTci1/OuS7E0fKffRbOstcYl6P2XmUddSX57JDRbRI+j0mu4yJvwU4gFMT2E0hQf71WPf61VSfESl2kv0wwinEc7H8PoZDMfw5hmcTyrv/BSIkzq/4tkbUqn10rcvaYuEtz+HkHew4+j1YJfU8GQy1xfRFEvNizbxe2FsQ+Y1KHrMgI3HakG6XnkNpY8NqPGLTITxKkvbdBeBJ1F1nDmiW7vdVgIheGQ2jM0SV8LYxkPnZ8K8yiwNRS2uYw8m92E6hldvVP3nkwAHoVLhZRHZKXAW4UGEyQjO3oTpOQxfhekERgcQ+xBltZubVPaArBGnV5KRyScytdbmV/wUouHovff3mlKn2iq+s9579rYOU5qevIe1x5uEBOZ5rfV4Q4+3iuywmDS2L1Qah25Z21YEL01Ps2hqCLyx23YyjJ6eCr5mYLUDbbulVD/9k4dBRfhJqMa+E+sJbCrctI479iq7fBpgcqMKF0P9rNjj8r6alDKt1JsZFytTItTPB032erGJOK01B9nbpabs32Ps7LplpHtJ/bImRts0rSru1SdN6jb5asYGyF46zNBiEbLDRSI0fRxLYE+jsITT0kggarqspioE1gSXvOn11oUsEofNs6Rr++V1fuQ5WQ7qfkWkya1q/6APZ73qEb0wTKDy2nMAodY2JjdhMoH4JhUx7zNzKMp7yIya43p/qN59QLUwRqh8AP2a8P1RTfzaqTcdVgSfjCuHYBzBVDswxbehV5uVhsIbOlpSR1LfuSkOXe456a/jsGTXjYZuuJvyqAf+pIb8+tiRn0TYlriNZG+TXkqap1pgLz2R5npwi+56042CfCyZlz1h/sPZhsp+cK0d9Mxz9v4UYqw23WU7x5OgBErdGMR+FeaRJBUvnjQ4Yo7Y+fvy3kHt6zzK4hlBtJlpNfV2TrKPoTeqSM+g3ver63FP5UUvNqnLx1NxZe/VC0/apsiv64UmrpXKqXi8+OQb2v50fV+f5+qnjw1I9kUnwizSSAhSrW4qnaa0UqRW/dsccvG/auKQi8zWiBsxW3DhLJO2fPCR2ffMXnfzSRi1NFWcVt71VH1/lFTtkHtkBrxF5XV/BXhTxakbNBlAdFhfu1GVRTyAsF+TVGz/WuMJ9Wqy0h48Wr+jfo84nkn98TlMpzAeVeexvs5ZdfxoDTrdHSi+ADEbrAbmSV4tMW3j4Wmmul552piFlei5CT06jJXwnkNz5yX7KtLVtdvaQyTOS5Cyz/VKp3pEnVcGMn7+gqhlvjLCbPqr7LWdb6VKQtJFLj57wdJRWkWINalkTLxs0t0mS0wN1Lm8a03CWC8aGWstINblFakkvVT4R1Nx6/eLg+p4OoVevRxWb1ydM4IwqRuOIY96BqJeqUYaWOkZsGq/R3J73ardFvq5VF3TKFH1vTQ8aW73aezwCDrPKbXutD1i2yWZrVor0PdhfiEIqai6O00Ia7uq9OZ9cC3ZRxV54nT+ca2kSFKD+kavV4fRyzsPmTUukZm2Jj0BZ3Wkb82/+7QP072KvGNZYmqvIntvv7req/0FQcbi9+u0me0H9cKTj6S/aCwTGMuxlJ1dnkokvjRWeskqGRSk/zEn30GQU51T5p0Ucsp/JHst2XWcufNy7DDZPZSoTouGz4Xxuk1SG8yzS3vj7QAarX56qlupzaYahKBUWJ2dOaskqA6CHkx7FREfLUQp/epWG5G9kEP+GVKXTawbw6hV/roheETyo4ro4bA6Zq/SAkKdhyDHYd7nKX6FXqzNlGmtRQiB7Y8lRBPQP6GA+cZUjnXDZjUniyaJnnLoeY1BLp322OBwWQ+XoeKXOulK7Xl5Vr+L16culV8qkl5YUavEUgG1Ha4JLiy0x3opKE9tFFKq/7r16hlwx6G6fJvZDLgjFd05lQA/D5U0Hfbg7AZMesy88fZdtC2sHVdSPrbRMxJMJD6HEOp8ByXZQ69qDOhV9x+p+r2q8Yi9qlGY1vsoZSIakEhpLa3tZlf4sdDv1FSnUlqWjqetL2k5bGi4bBNKHGTynI2vjXROhfVa75SKlpLg2qHWYzaMVZNfSxYroS15NaG1N197+XV+7Iq3te3b6818iDeoxsXIj1ZiHf95HcVZgLfqPrnhYc0B8S9Imt5adKmy8exMNQko1t1+Uc8U1Hu5flCR/5HTc09pHbpXQJel7rO3v4uyJlFOWyoVHjptfeyp8fb5VB0ut889rJnsA6r5lZ6zwaqlXtdJyn7xiCF7+TjWieLBhrPQ0jUw+2/ZAfNLH0vHta6okgdrGHsS0FtTDebtdm1naokl5aZ9BQeVWtw7gP4BHPTmFp59NK1VcBCrZGXo/lmAowEM92F8UtnF0wOYHvOom+zRO6lXjXX+ZY90rcVaxRYtpv4eMfXu8r3UWvMxAMNKwketUdmwumGUxsWSXPdwyDO68bL1xWuAS+HVWTuyLjrXJIzueYGLMw/Twm7NZN+jWiZFq6C24LXNZNVV28VgvadwUZpoWIltpRDMd314rbCukPonhbLem1zTkvWRYclFj7x+RiSVDFIRSSZpaweT/cmh7mrSP3eox7GHQ+gd1qvW9KvFKW5QbTeZTXXtxWre+n6sTe5epc7fH1TnD2/BcACjWzCqNZJovsGjT9aruvAeqdVjqv7yabWPNcGi/u4Sn3xfO4wY5tbsi8zCXdigWWjoemTXFLCaFMzIuAjR5zJt9looefXOklryVZ6P9ZI9DKD/ZNVtMtWqlbaZbD+yHS+uN90gaEI9SjCxYZ4Bf6iq7fO08Yj0jszUdVHJ9008gWoQiaje09m9KOkap9WcdJIySf2zfKziFnv9AHonsHcDBkdwo1+Nib/DTLLvT9XcFTWC7XxUT345qlT/W3V+Yj1uYDqutkhFzkj1TaUoplRTYidU8UxC7S2vu83G4yrceFyRfVLPrnu06ToyVu9vBYCuR56QsGPzvQbBwjYMnsYp8OpTSlDY5zxtRM49r7xuCKzw02n7WDPZD+Hg34KhdJnUH3puuqdMqrBdJnbtM9l0w2Alvy48bf95Be2p0PoazD6AxK+1EVGjYf5fZYFH3mPkkqii9fOx9lBHkei6313USimjh3VaD5hJcv2xZerpTQi3YO8IbtyBwz14aq+S6E8Ah5FwEKsacFpHdzYiPnwI0yFM3wIG0HuyWprqyX047sGdIziOM+VFXl/7wPS8GNmfU02dPZtWq9aeTmGi9meTSqMYTqv9OFYz9R6p/lIHpvjdaNoBZ7vPPA1R1xcrrVMET2mD+tiaER4BrWDxHJhS5zwtwGt0JC3bSMyw/kE1U1HbarI/+iDWK+pJ8pRKpit7TqVJqXPeh/H2tkLIdelf10u21l7l3gGEft2GhMobHsY8+tuKcDn2YCwkl/xJBZafFg65qLZLZdYVpl8NQOkdwcEh3N6Dkz7h2Ug4jvSfnNA7mjLYH9EfTAlnEYaReDZi8nBInI4ZT6fEGBnHWGngJ2E2qndMJf2HU5/sWvkYUU+bpZ5CW5P5vCb5KFb78aTai0QXmz5qrc7zqNs+c715dSd1npP+OU2gSYJrWPXf7nU8KZKXaCY+1kv26RiGLzIb8OCR3bbQWp3XH1B7gXOqldyX61P8DyQk6+O3vPpcwomNLf8Ll7+wHEDvdtXVtb8P/dohtgcMYjUZJNYVW8/veEil6nKfisxv1Bfln+aixmvHlry3dgQOYHADDh6DJ/bghw8JT0QGf2ZM//aY28++wf7xkFuHr3O4d0p/OqE/GTMa9TkfDhhO9rk/OmE47vHmmzA5h8kfUY2ReWUE98dwelZt01hnJdQ2uvpk53FG7GEtqc9rMo+jUv3rspCBMY/2luRWWltnmya5Lh8rncEXINqZB82k8sityWmFjxUuKe1S11Evb16e9PM+1izZJzC9T+WosR/JSnS91x82Jem9AtAfFtI2TWC+MK2TzpLe2lZiZ8u6b7L1ob9XDVJ51AMWZwM/mM53zYdY1w+dT+/9JG3vmpgLvUqL2OvDSY9wa8Lg8TH7d4bceuINjo5OuXf4MseDB+xNRwzimPPxHmejQx5OjwijHmejyMO9CfE0Mn0xEscBHk7g9SGcnsLDB9V7TJiRXX+qYS21h5OZej6aVOSeTFX2a7KLafNoQoztx9f/XLc+G+vHEWeeJQnqXEt3W9beuVwLzrGHdpI33UB4jZaO39MELmLNZD+F+PvMF7It2BSBvUJvekGrlrcp/JzjRaToCbPfq0gX3E0I+/UyTr1q6WYZkQaVukqstJvJsFZoItVc8kHtxJNpsbep7Pgj5ld/kQqu9/Ju9UySMIX+GI57hCen7D835N4Pv8ytu2/wZ25/jsf3X+aH4h/yeHyFo+kZB9MhD3rHvDa4zSs8zhf4E7x6fo9h/5g3X4tMX+4x+XqAr9yHP3oTJi/B+MU6aamkwRBYpHbduMfxTKuLejUeZmGT0li/qyBHilRd8a6lhIR3T661Ud/lGc+ut5uXR++9PAddTgvZhGTndcoKukR1smqRBxvP1H0qH0bSsGQfM1t5R5x/9Vrt/X5Fdt0LFyKPuqFirAlQpxdCrd5D5awLFdEfuQjEYZfSfOS9agdkDxhEwsGU3smUwcmIG7ff4tbNN3j66Ls83X+Bt4++wZOTlziOZxzGc+73Tnh1/w5H4YwX+08z7ffZPzhnsDcmDGO1is3rI3j1DOIDmLxhyqtnzrWDUaS0NtMkTK6i2/j099B7/VyKoE3HbdAk1TUsmZtI7uXLa8D0da+Rm8cGZr2pQRQLFbQOkyrsVOF5heHZOrnWXMheS+JH/1S7AeGoWpRxfwC3QnXrNvMDu0TlnQwqiT6JtbCur8UAk/2qMRgewXgKw1G1Htx0BJMzKrtdTzONzLr3jqF3A+4ew3N77P+xMTf/1Pd4/IlX+LM3/2+eGLzEe1/5LE+ev8zTL7zIzfv32ZuO2YsTbt59wM2n77N/NOLFe08xmI65vfcGo/19zgZHjPs96NXOwSh+FpEwnnNTyk1rcGJu9J1nPehv4Q00ScWRk/opeA1OCTTxtTmlzT1oJnaqbuqwUpZtNdWNkH3S+FQ7eBXMnqecGjjXcgVo70mlrUkf9iqJPujNxtjcYH6xmkmoTcsA475xcNUSfdKv1PpTajN1WvVDx3Nmo/NOma8ktfEf9isv/NE+PNan//iQ42cecPvua/zAwTd5JrzA29/6Fo+/9Qq3n3+Tw++d0Y+RXpwyOB0xOBhyNjnk7p3XeBiPOeyfsj84p9efEPqRGKaViXDB4y1l7kkrnU9LgKYytrDfO/X9bbpeV1UqXMk9nYZHSm9Un44zZW7k8mJJbgmfz+8Oz3pLtZLex29qsUtbdPloIqprD3zvpNqOjuDWAG4EeLq+fY/5vyaNqQaZjHt1txPVWu7TAKN+df4wGKFZ27+P+tdPmY2g03nZq7QLBnXxjOkPRuzvn3Nj7wFPTV/iqdGL3P3W69x6+T78v0PO/mjKZFL5y3pPTQjfPufk6df5Ib7G8eEp79z/Kse3HvLgmZsMHx4w+dYBce8m8BZMT5iZErYcdWUWiRTqPOtBIymSel5yay54ZPLi0vZ+iWNXwuXqkrfXWp8mux6nb/Olj1P1ro2GkcYOk13gtaq5ZzTaqEG6xRZpXjvPesdVV9fxATzWr4affl91iyeYdb/3gVGoSD4KMOpV+7NeJenPapIPmC0fN6R22sVadX5Ivbh7nX9pRU5mCYV63bfemF5vxP7eOcf9h9ybvsLj569w+ztvcvLtt3jwe3D+DTgbV6tFHz454eSlCcc/eJ+3PfstDu+e8QPPfZPeYMLXn3wnrz+8y/Rknzi4ARMZa6u7QKVMNcE8H4loInCRqDq89bBHE0avHdDk4JLeCzuzTR/DxTrhmSc5G9yO7fdGw9m8aQnt+SpWgytAdoFVFe29JhXO+yD2I9bLLQ1uVoNl9h+HvZtw4wRu1ER/Lla8e5ZqfPlxqKKWgSZvUnWjn8d69FhvNtq3T0XSE6pRarIAy4MAD3ow3oPRUdXFNakHJ0Ug9KqFIvuBwdE5vf0zDp6Ag3uROzce8tT4ezx2/j0OTocMTsfVAJpxYBxj1dZQjXvhPLD/eoDvRfa/O+Tk/CHP3fkO/cGUb9z+NuHpyBvvhIejwOS1wOjVYzgbwf1Tqq4y6Smw38JbpSdlPuluVdQ1TQi9tl2K7LrB0d86RVSdX3tszRPPDreSPZWfXF300rdaiD0vx46SvUlSLyKxvY8pexlrfrcm+b2qa+3OY3DjBjx+Ax4/rOb4/FCs/qf2VKwd9v1Ken+XilXfi/AC8FaE+9O6fvQqYj8eqv0dZiNmA9VElLMeDA/g7KQaaXdO1Y01HVWS/2RAOOizf/c++yen3B6ccnfwgLu3Tnnb+Ws803uJ4/un7J+OCacwPQ/VJNt+5OE4cB+YnvbYvBiM7AAABwdJREFUe6nH/gBOvnoGT77BH3vmKzx24zVeePwZjo7f4tsPHuOVeyecfjMw+cYt4vdOiQ9Hdb+5DHqxUk1GGFpiWS1A9rIJdEOhSW7JbuuCbTT095beDTsEOprnbJ3Qm60nmLxYaW0HQnkNh+w9UyZHdq+BmccGFq8QdWoVcbFAXFIgUnHsR9IFrofBHkL/VuX8OrwD+4dwcKNaIin2qoEjD8bw6nktsceVxB0dVg631/fhrK7wR7EaOrtfV5pemA28CbESs0Mqz3dvUqn741BNGhmPK6k+GVYDUaYBen3CjQGcDOCZQ3gsEB9Mmd4/Z3zW5/ylPg9ODnj56AkmYcBjj73KmMDkrSH922P6wwH90R4PBjd4a3CHcNKnf3+fs3DI83/4NG/cuMX50T7sB46fOeexI7i/V5Ft1O9z/p1Q81TIrgkgXRB9U94Ca497o9q8ATFaCuoRZ7YxScVliaLRVKeic6zfw1PLPXPE1kVMGJ1/m/5OSHbbF2vh2UxyvTSMhEvFJcdW7dLP6JVeTiDcgMHbYP8GPPY4HB08Up0ZD+G1c3hwH159BXpD2HtQxTF6EjiEw3vVzLNj4OkAg0G1yfcUFX8IvDytRpz13gLOq+683j5MTmF0H6ZnMHyjIvr0NuzvEe4dEp7Zgz95BG+D8Rde5fTzU/ovB1557ZTzxx9j8Nif4s7xm/T/xIh741e49ydf4fj8IQeTWwwnJ3xj9IP83vBHefjSIa/97k3G3+4x/GpkfGPAG//+PcY/sMeTP/4m33cy5JUv3+OlL93j/ufGvPwHfSIRpm9RDXHVU3N12WoJb6WxXNdDpafqXDcUY/WsHklo49Vk8aZK6zoQ1XVLMI+g+p7XgFjNRedBkOqS8zRUyxubJ733sUE13suYbRVLwqSQa/VsPLnCUhUiDKgmtwyqYbA9qqGvMdSa57TqD+/V0jfGesTctBow86gdCbMuel3HQp3vR71a0s0Vq7hkgohMAX20tnutGez1YD/AIcRBnxh7TGNgOgxMRj2GcZ8hB4z29hgPBsTYI+wFwqRHmPaZDPc5Ozvm4f4R9ycnTIYwmYyZhj7TaY/YC/T2p+wdTxgcT+kfBXr7odJMJO+u1PHU1lzD7d1LxWnTy0lBLw5rl1sCLZI/7zglob363kaz0PHkEWJsinh1CCG8zGzx8V3A4+xOXmG38rtLeYXdye/bYoxPeDfWSnaAEMLnYozvWWuiC2KX8gq7ld9dyivsXn49pIYxdejQ4YqhI3uHDtcEmyD7RzaQ5qLYpbzCbuV3l/IKu5ffC1i7zd6hQ4fNoFPjO3S4JujI3qHDNcHayB5C+KkQwpdDCF8NIXx4XemWIoTw/SGEz4QQvhhC+EII4Rfq64+FEP5FCOEr9f7upvMqCCH0QwifDyF8qj5/Rwjhs3UZ/2YIYb8pjnUhhHAnhPDxEMIfhBC+FEL4c9tatiGEv1XXgd8PIfyvIYTDbS7bUqyF7CGEPvA/Av8h8G7gL4cQ3r2OtFtgDPztGOO7gfcCf73O44eBT8cY3wV8uj7fFvwC8CV1/kvAL8cY3wm8BnxwI7ny8SvAP4sx/nHgR6nyvXVlG0J4FvgbwHtijD9CNZb259nusi1DjPHSN+DPAf9cnf8i8IvrSHuJPH8C+AvAl4Fn6mvPAF/edN7qvDxHRZCfBD5FNV7yFWDglfmG83ob+Dq1Q1hd37qypZqc/G3gMapBzZ8C/oNtLds227rUeClAwfP1ta1ECOHtwI8BnwWeijF+t771AtVE1m3APwD+DrOR9feA12OMsmzMNpXxO4CXgX9Ymx2/FkK4wRaWbYzxO8DfA75FNTH5DeB32N6yLUbnoDMIIZwA/wT4mzHGN/W9WDXrG++rDCH8ReClGOPvbDovhRgAfxr41Rjjj1HNj5hT2beobO8C76dqoL6Pajmen9poplaEdZH9O8D3q/Pn6mtbhRDCHhXRfz3G+Fv15RdDCM/U958BXtpU/hR+AvhLIYRvAL9Bpcr/CnAnhCAzGbepjJ8Hno8xfrY+/zgV+bexbP888PUY48sxxhHwW1Tlva1lW4x1kf23gXfVHs19KofHJ9eUdhFCCAH4KPClGOPfV7c+CXygPv4AlS2/UcQYfzHG+FyM8e1UZfkvY4x/BfgM8LP1Y1uRV4AY4wvAt0MIP1xfeh/wRbawbKnU9/eGEI7rOiF53cqybYU1Oj5+Gvg3wB8C/82mnRVO/v4dKjXy/wN+t95+msoW/jTwFeD/BB7bdF5Nvv894FP18Q8C/w/wVeAfAwebzp/K578NfK4u3/8NuLutZQv8d8AfAL8P/C9Uy4VubdmWbt1w2Q4drgk6B12HDtcEHdk7dLgm6MjeocM1QUf2Dh2uCTqyd+hwTdCRvUOHa4KO7B06XBP8//C5ap2djOONAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light",
            "tags": []
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(images.shape)\n",
        "imshow(torchvision.utils.make_grid(images, nrow=4))\n",
        "print(images.shape)\n",
        "print( (torchvision.utils.make_grid(images)).shape )\n",
        "print(''.join('%5s ' %classes[labels[j]] for j in range(1)))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "qIJFFik65k8E"
      },
      "source": [
        "# Facial Sensor 1D CNN Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqscNn-l5jyz",
        "outputId": "172be700-cc2b-4b4b-f839-6d37c057440c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "다음 기기로 학습합니다: cpu\n"
          ]
        }
      ],
      "source": [
        "################### 1d cnn model #######################################\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"train with the following device\", device)\n",
        "\n",
        "# fix random seed (for reproducibility)\n",
        "torch.manual_seed(777)\n",
        "\n",
        "# fix randome seed if GPU is available\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 999\n",
        "\n",
        "class CNN1d(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN1d, self).__init__()\n",
        "        # 1st layer (CNN)\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv1d(5, 16, 1),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.Tanh())\n",
        "\n",
        "        # 2nd layer (CNN)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv1d(16, 32, 1),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.Tanh())\n",
        "\n",
        "        # 3rd layer (CNN)\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv1d(32, 64, 1),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.Tanh())\n",
        "\n",
        "        # 4th layer (GAP)\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool1d(1),\n",
        "            nn.Tanh())\n",
        "\n",
        "        # 5th layer (FC)\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Linear(64, 5, bias=True),\n",
        "            nn.Tanh())\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        out = self.layer5(out)\n",
        "        return out\n",
        "\n",
        "# define CNN model\n",
        "model_facial = CNN1d().to(device)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm6FAiwU2spy"
      },
      "source": [
        "# Vocal Sensor 2D CNN Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MI2b2Zq4Kx9b",
        "outputId": "1fe18c17-0183-4370-d62f-b59b8bcea6b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "다음 기기로 학습합니다: cpu\n"
          ]
        }
      ],
      "source": [
        "################### 2d cnn model #######################################\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import copy\n",
        "from torch.utils.data import TensorDataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"train with the following device\", device)\n",
        "\n",
        "# fix random seed (for reproducibility)\n",
        "torch.manual_seed(777)\n",
        "\n",
        "# fix randome seed if GPU is available\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "learning_rate = 0.001\n",
        "training_epochs = 199\n",
        "\n",
        "class CNN2d(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(CNN2d, self).__init__()\n",
        "        # 1st layer (CNN)\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 32, 3),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        # 2nd layer (CNN)\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(32, 64, 3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        # 3rd layer (CNN)\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(64, 128, 3),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Tanh(),\n",
        "            nn.MaxPool2d(2))\n",
        "\n",
        "        # 4th layer (GAP)\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1),\n",
        "            nn.Tanh())\n",
        "\n",
        "        # 5th layer (FC)\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Linear(128, 5, bias=True),\n",
        "            nn.Softmax(dim=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        out = self.layer5(out)\n",
        "        return out\n",
        "\n",
        "# define CNN model\n",
        "model_vocal = CNN2d().to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T5Au-s1t5Qj"
      },
      "source": [
        "#Pre-Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22meNjaR1gv7"
      },
      "source": [
        "## Facial sensor_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2kgNSJ_xOIZ"
      },
      "outputs": [],
      "source": [
        "#########facial sensor_training################\n",
        "\n",
        "# define cost function and optimizer\n",
        "criterion = nn.CrossEntropyLoss().to(device) # softmax is included in the cost function\n",
        "optimizer = torch.optim.Adam(model_facial.parameters(), lr=learning_rate)\n",
        "\n",
        "total_batch = len(train_dataloader_f)\n",
        "print('total number of the batches : {}'.format(total_batch))\n",
        "\n",
        "for epoch in range(training_epochs + 1):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X_train, Y_train in train_dataloader_f:\n",
        "        X_train = X_train.to(device)\n",
        "        Y_train = Y_train.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model(X_train)\n",
        "        cost = criterion(hypothesis, Y_train)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
        "\n",
        "################################ Testing (trainset) #######################################\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in train_dataloader_f:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_vocal(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    ################################ Testing (testset) #######################################\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in test_dataloader_f:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_vocal(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "        if correct_test / total_test > best_test_acc:\n",
        "            best_epoch = epoch\n",
        "            best_cost = avg_cost.item()\n",
        "            best_train_acc = correct_train / total_train\n",
        "            best_test_acc = correct_test / total_test\n",
        "            best_model_wts = copy.deepcopy(model_vocal.state_dict())\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:.4f}'.format(epoch + 1, avg_cost),\n",
        "          'trainset acc.: %{:.2f} %%' % (100 * correct_train / total_train),\n",
        "          'testset acc.: %{:.2f} %%' % (100 * correct_test / total_test))\n",
        "\n",
        "print('best condition : ', 'epoch: {:>4} cost = {:.4f}'.format(best_epoch + 1, best_cost),\n",
        "      'trainset acc.: %{:.2f} %%' % (100 * best_test_acc),\n",
        "      'trainset acc.: %{:.2f} %%' % (100 * best_test_acc))\n",
        "\n",
        "############## store the model #################\n",
        "PATH = F\" \" #수정\n",
        "torch.save(best_model_wts, PATH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4ucuZP1F1uRC"
      },
      "source": [
        "## Vocal sensor_training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IiK_Hx_oK3jC"
      },
      "outputs": [],
      "source": [
        "#########vocal sensor_training################\n",
        "\n",
        "# defien cost function and optimizer\n",
        "criterion = nn.CrossEntropyLoss().to(device) # softmax is included in the cost function\n",
        "optimizer = torch.optim.Adam(model_vocal.parameters(), lr=learning_rate)\n",
        "\n",
        "total_batch = len(train_dataloader_v)\n",
        "print('total number of the batches : {}'.format(total_batch))\n",
        "\n",
        "best_model_wts = copy.deepcopy(model_vocal.state_dict())\n",
        "best_epoch = 0\n",
        "best_cost = 0.0\n",
        "best_train_acc = 0.0\n",
        "best_test_acc = 0.0\n",
        "\n",
        "for epoch in range(training_epochs + 1):\n",
        "    avg_cost = 0\n",
        "\n",
        "    for X_train, Y_train in train_dataloader_v:\n",
        "        X_train = X_train.to(device)\n",
        "        Y_train = Y_train.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = model_vocal(X_train)\n",
        "        #print(hypothesis)\n",
        "        cost = criterion(hypothesis, Y_train)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "    print('[Epoch: {:>4}] cost = {:>.9}'.format(epoch + 1, avg_cost))\n",
        "\n",
        "    ################################ Testing (trainset) #######################################\n",
        "    correct_train = 0\n",
        "    total_train = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in train_dataloader_v:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_vocal(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_train += labels.size(0)\n",
        "            correct_train += (predicted == labels).sum().item()\n",
        "\n",
        "    ################################ Testing (testset) #######################################\n",
        "    correct_test = 0\n",
        "    total_test = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in test_dataloader_v:\n",
        "            images, labels = data\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model_vocal(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total_test += labels.size(0)\n",
        "            correct_test += (predicted == labels).sum().item()\n",
        "\n",
        "        if correct_test / total_test > best_test_acc:\n",
        "            best_epoch = epoch\n",
        "            best_cost = avg_cost.item()\n",
        "            best_train_acc = correct_train / total_train\n",
        "            best_test_acc = correct_test / total_test\n",
        "            best_model_wts = copy.deepcopy(model_vocal.state_dict())\n",
        "\n",
        "    print('[Epoch: {:>4}] cost = {:.4f}'.format(epoch + 1, avg_cost),\n",
        "          'trainset acc.: %{:.2f} %%' % (100 * correct_train / total_train),\n",
        "          'testset acc.: %{:.2f} %%' % (100 * correct_test / total_test))\n",
        "\n",
        "print('best condition : ', 'epoch: {:>4} cost = {:.4f}'.format(best_epoch + 1, best_cost),\n",
        "      'trainset acc.: %{:.2f} %%' % (100 * best_test_acc),\n",
        "      'trainset acc.: %{:.2f} %%' % (100 * best_test_acc))\n",
        "\n",
        "############## store the model #################\n",
        "PATH = F\"\" #수정\n",
        "torch.save(best_model_wts, PATH)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "FJGxGi8UqO2o",
        "44-_hqLh1TgW",
        "VXNb6vP_1bj_",
        "EXiv8lDO1u_z",
        "qIJFFik65k8E",
        "Mm6FAiwU2spy",
        "22meNjaR1gv7",
        "4ucuZP1F1uRC",
        "uGLzQrCDuBRF"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
